{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b21376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/VegardEikenes/Desktop/Bachelor/Data/BraTS2021_TrainingData/'\n",
    "VOLUME_SLICES = 100\n",
    "VOLUME_START_AT = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81559fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This generator was originally written by Rastislav: https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net \n",
    "with inspiration from: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "The generator has been modified to include an increased number of modalities, and can easily be\n",
    "adapted. \n",
    "\"\"\"\n",
    "\n",
    "class DataGenerator2D(keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, dim=(128, 128), batch_size = 1, n_channels = 3, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii')\n",
    "            flair = nib.load(data_path).get_fdata()    \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii')\n",
    "            t1ce = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii')\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "#             data_path = os.path.join(case_path, f'{i}_t1.nii')\n",
    "#             t1 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii')\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], dim)\n",
    "                X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], dim)\n",
    "                X[j +VOLUME_SLICES*c,:,:,2] = cv2.resize(t2[:,:,j+VOLUME_START_AT], dim)\n",
    "#                 X[j +VOLUME_SLICES*c,:,:,2] = cv2.resize(t1[:,:,j+VOLUME_START_AT], dim)\n",
    "\n",
    "                y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        y[y==4] = 3\n",
    "        mask = tf.one_hot(y, 4)\n",
    "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This 3D generator is inspired from \n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "The generator is written to generate 3D volumes from NIfTI files on the fly while training. The\n",
    "number of modalities to include can easily be adapted. The generator does however only accept batch\n",
    "sizes of 1. This is not an issue for my project as increasing the batch size to 2 would \n",
    "cause memory exhaustion. \n",
    "\"\"\"\n",
    "\n",
    "class DataGenerator3D(keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, batch_size = 1, n_channels = 3, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii')\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii')\n",
    "            t1ce = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii')\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "#             data_path = os.path.join(case_path, f'{i}_t1.nii')\n",
    "#             t1 = nib.load(data_path).get_fdata()\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii')\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "            seg[seg==4] = 3\n",
    "            \n",
    "            stack = np.stack([flair, t1ce, t2], axis=3)\n",
    "            stack = stack[56:184, 56:184, 13:141]\n",
    "            seg = seg[56:184, 56:184, 13:141]\n",
    "            \n",
    "        Y = tf.one_hot(seg, 4)\n",
    "        Y = tf.expand_dims(Y, 0)\n",
    "        X = np.expand_dims(stack, 0)\n",
    "        return X/np.max(X), Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
