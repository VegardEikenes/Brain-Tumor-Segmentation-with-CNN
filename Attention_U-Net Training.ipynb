{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5039c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import PIL\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Datagens import *\n",
    "from AttentionUnet import *\n",
    "from metrics import *\n",
    "\n",
    "# ml libs\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "CSVLogger.on_test_begin = CSVLogger.on_train_begin\n",
    "CSVLogger.on_test_batch_end = CSVLogger.on_epoch_end\n",
    "CSVLogger.on_test_end = CSVLogger.on_train_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6662f9c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The argument `strides` cannot contains 0(s). Received: (0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_attention_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mker_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhe_normal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMeanIoU(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), dice_coef, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )\n",
      "File \u001b[1;32m~\\Desktop\\Bachelor\\Code\\AttentionUnet.py:41\u001b[0m, in \u001b[0;36mbuild_attention_unet\u001b[1;34m(n_channels, ker_init, dropout, batchnorm)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Upsampling layers\u001b[39;00m\n\u001b[0;32m     40\u001b[0m gating_5 \u001b[38;5;241m=\u001b[39m gatingsignal(conv5, \u001b[38;5;241m128\u001b[39m, batchnorm)\n\u001b[1;32m---> 41\u001b[0m att_5 \u001b[38;5;241m=\u001b[39m \u001b[43mattention_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgating_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m up_5 \u001b[38;5;241m=\u001b[39m UpSampling2D(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))(drop5)\n\u001b[0;32m     43\u001b[0m up_5 \u001b[38;5;241m=\u001b[39m concatenate([up_5, att_5], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\Bachelor\\Code\\attention_blocks.py:21\u001b[0m, in \u001b[0;36mattention_block\u001b[1;34m(x, gating, inter_shape)\u001b[0m\n\u001b[0;32m     19\u001b[0m shape_theta_x \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mint_shape(theta_x)\n\u001b[0;32m     20\u001b[0m phi_g \u001b[38;5;241m=\u001b[39m Conv2D(inter_shape, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(gating)\n\u001b[1;32m---> 21\u001b[0m upsample_g \u001b[38;5;241m=\u001b[39m \u001b[43mConv2DTranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43minter_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshape_theta_x\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshape_g\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_theta_x\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshape_g\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhe_normal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m(phi_g)\n\u001b[0;32m     22\u001b[0m concat_xg \u001b[38;5;241m=\u001b[39m add([upsample_g, theta_x])\n\u001b[0;32m     23\u001b[0m act_xg \u001b[38;5;241m=\u001b[39m Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(concat_xg)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\layers\\convolutional.py:1224\u001b[0m, in \u001b[0;36mConv2DTranspose.__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, output_padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1207\u001b[0m              filters,\n\u001b[0;32m   1208\u001b[0m              kernel_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1222\u001b[0m              bias_constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1223\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1224\u001b[0m   \u001b[38;5;28msuper\u001b[39m(Conv2DTranspose, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1225\u001b[0m       filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m   1226\u001b[0m       kernel_size\u001b[38;5;241m=\u001b[39mkernel_size,\n\u001b[0;32m   1227\u001b[0m       strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[0;32m   1228\u001b[0m       padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   1229\u001b[0m       data_format\u001b[38;5;241m=\u001b[39mdata_format,\n\u001b[0;32m   1230\u001b[0m       dilation_rate\u001b[38;5;241m=\u001b[39mdilation_rate,\n\u001b[0;32m   1231\u001b[0m       activation\u001b[38;5;241m=\u001b[39mactivations\u001b[38;5;241m.\u001b[39mget(activation),\n\u001b[0;32m   1232\u001b[0m       use_bias\u001b[38;5;241m=\u001b[39muse_bias,\n\u001b[0;32m   1233\u001b[0m       kernel_initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer),\n\u001b[0;32m   1234\u001b[0m       bias_initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mget(bias_initializer),\n\u001b[0;32m   1235\u001b[0m       kernel_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(kernel_regularizer),\n\u001b[0;32m   1236\u001b[0m       bias_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(bias_regularizer),\n\u001b[0;32m   1237\u001b[0m       activity_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(activity_regularizer),\n\u001b[0;32m   1238\u001b[0m       kernel_constraint\u001b[38;5;241m=\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mget(kernel_constraint),\n\u001b[0;32m   1239\u001b[0m       bias_constraint\u001b[38;5;241m=\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mget(bias_constraint),\n\u001b[0;32m   1240\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1242\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_padding \u001b[38;5;241m=\u001b[39m output_padding\n\u001b[0;32m   1243\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_padding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\layers\\convolutional.py:673\u001b[0m, in \u001b[0;36mConv2D.__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    656\u001b[0m              filters,\n\u001b[0;32m    657\u001b[0m              kernel_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    671\u001b[0m              bias_constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    672\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 673\u001b[0m   \u001b[38;5;28msuper\u001b[39m(Conv2D, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    674\u001b[0m       rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    675\u001b[0m       filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    676\u001b[0m       kernel_size\u001b[38;5;241m=\u001b[39mkernel_size,\n\u001b[0;32m    677\u001b[0m       strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[0;32m    678\u001b[0m       padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    679\u001b[0m       data_format\u001b[38;5;241m=\u001b[39mdata_format,\n\u001b[0;32m    680\u001b[0m       dilation_rate\u001b[38;5;241m=\u001b[39mdilation_rate,\n\u001b[0;32m    681\u001b[0m       groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    682\u001b[0m       activation\u001b[38;5;241m=\u001b[39mactivations\u001b[38;5;241m.\u001b[39mget(activation),\n\u001b[0;32m    683\u001b[0m       use_bias\u001b[38;5;241m=\u001b[39muse_bias,\n\u001b[0;32m    684\u001b[0m       kernel_initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer),\n\u001b[0;32m    685\u001b[0m       bias_initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mget(bias_initializer),\n\u001b[0;32m    686\u001b[0m       kernel_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(kernel_regularizer),\n\u001b[0;32m    687\u001b[0m       bias_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(bias_regularizer),\n\u001b[0;32m    688\u001b[0m       activity_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(activity_regularizer),\n\u001b[0;32m    689\u001b[0m       kernel_constraint\u001b[38;5;241m=\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mget(kernel_constraint),\n\u001b[0;32m    690\u001b[0m       bias_constraint\u001b[38;5;241m=\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mget(bias_constraint),\n\u001b[0;32m    691\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\layers\\convolutional.py:159\u001b[0m, in \u001b[0;36mConv.__init__\u001b[1;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_constraint \u001b[38;5;241m=\u001b[39m constraints\u001b[38;5;241m.\u001b[39mget(bias_constraint)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m InputSpec(min_ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_causal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channels_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\layers\\convolutional.py:177\u001b[0m, in \u001b[0;36mConv._validate_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe argument `kernel_size` cannot contain 0(s). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    174\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,))\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrides):\n\u001b[1;32m--> 177\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe argument `strides` cannot contains 0(s). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    178\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrides,))\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m                                                 (Conv1D, SeparableConv1D))):\n\u001b[0;32m    182\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCausal padding is only supported for `Conv1D`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    183\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand `SeparableConv1D`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The argument `strides` cannot contains 0(s). Received: (0, 0)"
     ]
    }
   ],
   "source": [
    "model = build_attention_unet(n_channels=3, ker_init='he_normal', dropout=0.2)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "train_and_test_ids = pathListIntoIds(train_and_val_directories); \n",
    "\n",
    "    \n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids,train_size=236, test_size=60, random_state=14) \n",
    "train_ids, test_ids = train_test_split(train_test_ids,test_size=36, random_state=14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b103f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c85917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
    "            flair = nib.load(data_path).get_fdata()    \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
    "            ce = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii');\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                X[j +VOLUME_SLICES*c,:,:,2] = cv2.resize(t2[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                \n",
    "                y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "                    \n",
    "        # Generate masks\n",
    "        y[y==4] = 3;\n",
    "        mask = tf.one_hot(y, 4);\n",
    "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        return X/np.max(X), Y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e99851",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('Logs/training/attU_net_2d_batch.log', separator=',', append=False)\n",
    "\n",
    "eval_csv_logger = CSVLogger('Logs/testing/attU_net_2d_batch.log', separator=',', append=False)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1),\n",
    "        csv_logger\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "history =  model.fit(training_generator,\n",
    "                    epochs=100,\n",
    "                    steps_per_epoch=len(train_ids),\n",
    "                    callbacks= callbacks,\n",
    "                    validation_data = valid_generator\n",
    "                    )  \n",
    "model.save(\"Models/attU_net_2d_batch2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55aaad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=history.history\n",
    "\n",
    "acc=hist['accuracy']\n",
    "val_acc=hist['val_accuracy']\n",
    "\n",
    "epoch=range(len(acc))\n",
    "\n",
    "loss=hist['loss']\n",
    "val_loss=hist['val_loss']\n",
    "\n",
    "train_dice=hist['dice_coef']\n",
    "val_dice=hist['val_dice_coef']\n",
    "\n",
    "f,ax=plt.subplots(1,4,figsize=(16,8))\n",
    "\n",
    "ax[0].plot(epoch,acc,'b',label='Training Accuracy')\n",
    "ax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epoch,loss,'b',label='Training Loss')\n",
    "ax[1].plot(epoch,val_loss,'r',label='Validation Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(epoch,train_dice,'b',label='Training dice coef')\n",
    "ax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\n",
    "ax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\n",
    "ax[3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d887764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Models/2D/attU_net_2d.h5', \n",
    "                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "                                                   \"dice_coef\": dice_coef,\n",
    "                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n",
    "                                                   \"dice_coef_edema\": dice_coef_edema,\n",
    "                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n",
    "                                                  }, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator, callbacks=eval_csv_logger, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c939087",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_csv_logger = CSVLogger('Logs/validation/attU_net_2d_batch2.log', separator=',', append=False)\n",
    "model.evaluate(valid_generator, callbacks=valid_csv_logger, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772955f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
